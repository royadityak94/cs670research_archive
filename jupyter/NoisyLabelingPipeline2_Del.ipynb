{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import io\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import xml.etree.ElementTree as ET \n",
    "from google.cloud import vision\n",
    "import requests\n",
    "from nltk.corpus import stopwords as stpword\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import json\n",
    "from nltk.corpus import stopwords as stpword\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from utilities.image_description_scoring import matching_label_score\n",
    "from time import time\n",
    "from utilities.pythonDB import writeToDB_label, recordsExists_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stpword.words('english'))\n",
    "wordNetLemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_clean_list(original_list):\n",
    "    cleaned = list(set([wordNetLemma.lemmatize(obj_item.lower().strip()) for item in original_list for obj_item in item.split() if obj_item not in stopwords]))\n",
    "    return [item.strip() for item in [re.sub('[^a-zA-Z0-9]+', ' ', item, flags=re.UNICODE) for item in cleaned]]\n",
    "\n",
    "def get_mapped(path):\n",
    "    key_map, dict_idx = {}, 0\n",
    "    for r, _, f in os.walk(path):\n",
    "        for file in f:\n",
    "            if '.JPG' in file or '.jpg' in file:\n",
    "                key_map[dict_idx] = file\n",
    "                dict_idx += 1\n",
    "    idxs = list(key_map.keys())          \n",
    "    shuffled_idxs = np.random.randint(0, len(idxs), len(idxs))\n",
    "    return key_map, shuffled_idxs\n",
    "\n",
    "def get_captions(base_path, annotation_file):\n",
    "    with open(os.path.join(base_path, annotation_file)) as json_file:\n",
    "        caption_file = json.load(json_file)\n",
    "    captions, mapped_annotation = {}, {}\n",
    "\n",
    "    for annotation in caption_file['annotations']:\n",
    "        mapped_annotation[annotation['image_id']] = annotation['caption']\n",
    "\n",
    "    for image in caption_file['images']:\n",
    "        captions[image['file_name']] = mapped_annotation.get(image['id'])\n",
    "    return captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectLabels():\n",
    "    def __init__(self, base, file, max_labels=30):\n",
    "        \n",
    "        with io.open(os.path.join(base, file), 'rb') as image_file:\n",
    "            content = (image_file.read())\n",
    "        self.content = content\n",
    "        self.base, self.actual_str, self.detected_str = base, '', '' \n",
    "        self.file = file.split('_')[-1]\n",
    "        \n",
    "        self.label = ''\n",
    "        self.start = time()\n",
    "        self.max_labels = max_labels\n",
    "        \n",
    "    def return_function(self, name):\n",
    "        dataset = self.base.split('/')[1]\n",
    "        if recordsExists_label(self.file, dataset, name):\n",
    "            return\n",
    "        \n",
    "        status, score =  getattr(self, 'if_' + name)()\n",
    "        compute_time = time() - self.start\n",
    "        self.label = name + '-noisy'\n",
    "        \n",
    "        score1, score2, score3 = score[0], score[1], score[2]\n",
    "        \n",
    "        bag = (self.file, dataset, self.label, status, score1, score2, score3, compute_time, self.actual_str, self.detected_str)\n",
    "        print (bag)\n",
    "        writeToDB_label(bag)\n",
    "        \n",
    "    def compute_ground_truth(self):\n",
    "        ''' Status = {-1:'API Error', -2: 'Ground Truth Empty', 0: 'All Correct'}, Return = Ground Truth, Status\n",
    "        '''\n",
    "        ground_truth_str = captions.get(self.file)\n",
    "        \n",
    "        if ground_truth_str is None or len(ground_truth_str) == 0:\n",
    "            return '', -2\n",
    "        else:\n",
    "            ground_truth_str = extract_clean_list(ground_truth_str.lower().split(' '))\n",
    "            self.actual_str = ground_truth_str\n",
    "            return ground_truth_str, 0\n",
    "            \n",
    "    def if_aws(self):\n",
    "        ground_truth, xml_status = self.compute_ground_truth()\n",
    "        if xml_status != 0: return xml_status, 0\n",
    "        \n",
    "        try:\n",
    "            imgobj = {'Bytes': self.content}\n",
    "            client=boto3.client('rekognition', region_name='us-east-1')\n",
    "            response=client.detect_labels(Image=imgobj, MaxLabels=self.max_labels)\n",
    "            detected_label = [label['Name'] for label in response['Labels']]\n",
    "            score1 = matching_label_score(detected_label, ground_truth, 1)\n",
    "            score2 = matching_label_score(detected_label, ground_truth, 2)\n",
    "            score3 = matching_label_score(detected_label, ground_truth, 3)\n",
    "            score = [score1, score2, score3]\n",
    "            \n",
    "            self.detected_str = detected_label\n",
    "            return 0, score\n",
    "        except:\n",
    "            return -1, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterating for File Name = add_impulse_noise_2_000000405530.jpg\n",
      "('000000405530.jpg', 'image_labeling', 'aws-noisy', 0, 1, 1, 1, 0.7973294258117676, ['man', 'sitting', 'statue', 'bench'], ['Water', 'Outdoors', 'Nature', 'Human', 'Person', 'Waterfront', 'Sundial', 'Pier', 'Port', 'Dock', 'Hook', 'Sea', 'Ocean', 'Landscape'])\n"
     ]
    }
   ],
   "source": [
    "annotation_dir_path = 'datasets/image_labeling/annotations'\n",
    "train_dir_path = 'datasets/image_labeling/noises'\n",
    "captions_validation = get_captions(annotation_dir_path, 'captions_val2017.json')\n",
    "captions = get_captions(annotation_dir_path, 'captions_train2017.json')\n",
    "captions.update(captions_validation)\n",
    "del captions_validation\n",
    "dict_files, files_idx = get_mapped(train_dir_path)\n",
    "shuffled_idx = np.random.randint(0, len(files_idx), len(files_idx))[:1]\n",
    "\n",
    "for idx in shuffled_idx:\n",
    "    file_name = dict_files.get(idx)\n",
    "    print (\"Iterating for File Name = {}\".format(file_name))\n",
    "    DetectLabels(train_dir_path, file_name).return_function('aws')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cs682)",
   "language": "python",
   "name": "cs682"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
