{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(sent1, sent2):\n",
    "    intersection = len(list(set(sent1).intersection(set(sent2))))\n",
    "    union = min(len(sent1), len(sent2))\n",
    "    return (intersection / union)\n",
    "\n",
    "def cosineValue(v1,v2):\n",
    "    \"compute cosine similarity of v1 to v2: (v1 dot v2)/{||v1||*||v2||)\"\n",
    "    sumxx, sumxy, sumyy = 0, 0, 0\n",
    "    for i in range(len(v1)):\n",
    "        x = v1[i]; y = v2[i]\n",
    "        sumxx += x*x\n",
    "        sumyy += y*y\n",
    "        sumxy += x*y\n",
    "    return sumxy/np.sqrt(sumxx*sumyy)\n",
    "\n",
    "def get_sentence_vector(sentence, std_embeddings_index = std_embeddings_index ):\n",
    "    sent_vector = 0\n",
    "    for word in sentence.lower().split():\n",
    "        if word not in std_embeddings_index :\n",
    "            word_vector = np.array(np.random.uniform(-1.0, 1.0, 300))\n",
    "            std_embeddings_index[word] = word_vector\n",
    "        else:\n",
    "            word_vector = std_embeddings_index[word]\n",
    "        sent_vector = sent_vector + word_vector\n",
    "    return sent_vector\n",
    "\n",
    "def cosine_sim(sent1, sent2):\n",
    "    global std_embeddings_index\n",
    "    std_embeddings_index = {}\n",
    "    with io.open(\"datasets/cached_embeddings.txt\", \"r\", encoding=\"utf-8\") as my_file:\n",
    "        for line in my_file:\n",
    "            values = line.split(' ')\n",
    "            word = values[0]\n",
    "            embedding = np.asarray(values[1:], dtype='float32')\n",
    "            std_embeddings_index[word] = embedding\n",
    "            \n",
    "    return cosineValue(get_sentence_vector(sent1), get_sentence_vector(sent2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_similarity('Iced Coffee', 'Ice Coffee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global std_embeddings_index\n",
    "    std_embeddings_index = {}\n",
    "    with io.open(\"datasets/cached_embeddings.txt\", \"r\", encoding=\"utf-8\") as my_file:\n",
    "        for line in my_file:\n",
    "            values = line.split(' ')\n",
    "            word = values[0]\n",
    "            embedding = np.asarray(values[1:], dtype='float32')\n",
    "            std_embeddings_index[word] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(std_embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    \"\"\" Special json encoder for numpy types \"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (np.int_, np.intc, np.intp, np.int8,\n",
    "            np.int16, np.int32, np.int64, np.uint8,\n",
    "            np.uint16, np.uint32, np.uint64)):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, (np.float_, np.float16, np.float32, \n",
    "            np.float64)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj,(np.ndarray,)): #### This is the fix\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "std_embeddings_index_json = json.dumps(std_embeddings_index, cls=NumpyEncoder)\n",
    "# with open('datasets/embedded_similarity_dict.json', 'w') as f:\n",
    "#     json.dump(std_embeddings_index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "my_dict = {}\n",
    "with open('datasets/embedded_similarity_dict.json') as f:\n",
    "    my_dict = json.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cs682)",
   "language": "python",
   "name": "cs682"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
